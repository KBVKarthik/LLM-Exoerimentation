{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":54662,"databundleVersionId":6169864,"sourceType":"competition"},{"sourceId":4620664,"sourceType":"datasetVersion","datasetId":2663421},{"sourceId":6175087,"sourceType":"datasetVersion","datasetId":3540289},{"sourceId":6281449,"sourceType":"datasetVersion","datasetId":3611733},{"sourceId":6572938,"sourceType":"datasetVersion","datasetId":3600418}],"dockerImageVersionId":30528,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# installing offline dependencies\n\n!pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/datasets-2.14.3-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-15T09:47:17.705103Z","iopub.execute_input":"2024-02-15T09:47:17.705403Z","iopub.status.idle":"2024-02-15T09:47:35.557286Z","shell.execute_reply.started":"2024-02-15T09:47:17.705377Z","shell.execute_reply":"2024-02-15T09:47:35.556002Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.30.2\n    Uninstalling transformers-4.30.2:\n      Successfully uninstalled transformers-4.30.2\nSuccessfully installed transformers-4.31.0\nProcessing /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\nInstalling collected packages: peft\nSuccessfully installed peft-0.4.0\nProcessing /kaggle/input/llm-whls/datasets-2.14.3-py3-none-any.whl\nInstalling collected packages: datasets\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\nSuccessfully installed datasets-2.14.3\nProcessing /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl\nInstalling collected packages: trl\nSuccessfully installed trl-0.5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# using single gpu for this case\n\nimport os\nos.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:47:35.559605Z","iopub.execute_input":"2024-02-15T09:47:35.559934Z","iopub.status.idle":"2024-02-15T09:47:35.565036Z","shell.execute_reply.started":"2024-02-15T09:47:35.559906Z","shell.execute_reply":"2024-02-15T09:47:35.564096Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nfrom datasets import load_dataset, Dataset\nfrom peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model, PeftModel, PeftConfig, TaskType, PeftModelForSequenceClassification\nfrom tqdm.auto import tqdm\nfrom transformers import (\n    AutoModelForSequenceClassification, AutoModelForCausalLM, AutoModel,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    DataCollatorWithPadding\n)\n\nimport random\nimport os\nimport gc\n\n\n\nfrom trl import RewardTrainer\n\nimport pandas as pd\npd.set_option('display.max_colwidth', None)\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:47:35.566154Z","iopub.execute_input":"2024-02-15T09:47:35.566438Z","iopub.status.idle":"2024-02-15T09:47:50.957065Z","shell.execute_reply.started":"2024-02-15T09:47:35.566414Z","shell.execute_reply":"2024-02-15T09:47:50.956069Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"class CFG:\n    base_model = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-large\"\n    seed = 42","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:47:50.959368Z","iopub.execute_input":"2024-02-15T09:47:50.959709Z","iopub.status.idle":"2024-02-15T09:47:50.964255Z","shell.execute_reply.started":"2024-02-15T09:47:50.959665Z","shell.execute_reply":"2024-02-15T09:47:50.963188Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = int):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\n\nrandom_state = set_seed(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:47:50.965979Z","iopub.execute_input":"2024-02-15T09:47:50.966229Z","iopub.status.idle":"2024-02-15T09:47:51.008454Z","shell.execute_reply.started":"2024-02-15T09:47:50.966208Z","shell.execute_reply":"2024-02-15T09:47:51.007464Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# loading multi option dataset\n\ntrain_df_0 = pd.read_csv('/kaggle/input/additional-train-data-for-llm-science-exam/6000_train_examples.csv')\ntrain_df_1 = pd.read_csv('/kaggle/input/additional-train-data-for-llm-science-exam/extra_train_set.csv')\ntest_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv')\n\n\n# merge and drop empty lines\n\ntrain_df = pd.concat((train_df_0, train_df_1), axis=0)\ntrain_df.dropna(inplace=True)\ntrain_df.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:47:51.009925Z","iopub.execute_input":"2024-02-15T09:47:51.010219Z","iopub.status.idle":"2024-02-15T09:47:51.186853Z","shell.execute_reply.started":"2024-02-15T09:47:51.010193Z","shell.execute_reply":"2024-02-15T09:47:51.186055Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def generate_new_dataframe(df):\n    new_rows = []\n\n    # Iterate through each row in the original DataFrame\n    for _, row in df.iterrows():\n        prompt = row['prompt']\n        chosen_option = row[row['answer']]  # Get the text of the chosen option based on the 'answer' column\n\n        # Iterate through each option\n        for option in ['A', 'B', 'C', 'D', 'E']:\n            if option != row['answer']:\n                rejected_option = row[option]  # Get the text of the rejected option\n                new_row = {'chosen': prompt + ' ' + chosen_option, 'rejected': prompt + ' ' + rejected_option}\n                new_rows.append(new_row)\n\n    # Create a new DataFrame from the new_rows list\n    new_df = pd.DataFrame(new_rows)\n    return new_df\n\n\ntrain_df = generate_new_dataframe(train_df)\ntest_df = generate_new_dataframe(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:47:51.187998Z","iopub.execute_input":"2024-02-15T09:47:51.188300Z","iopub.status.idle":"2024-02-15T09:47:51.940695Z","shell.execute_reply.started":"2024-02-15T09:47:51.188273Z","shell.execute_reply":"2024-02-15T09:47:51.939703Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# adding extra reward data\n\ntrain_df_2 = pd.read_csv('/kaggle/input/rlhf-data-for-llm-science-exam/llm_rlhf_extra.csv')\ntrain_df = pd.concat((train_df, train_df_2), axis=0)\ntrain_df = train_df.sample(frac=1.0, random_state=CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:47:51.942183Z","iopub.execute_input":"2024-02-15T09:47:51.942529Z","iopub.status.idle":"2024-02-15T09:47:52.037780Z","shell.execute_reply.started":"2024-02-15T09:47:51.942502Z","shell.execute_reply":"2024-02-15T09:47:52.036641Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# converting to dataset format\n\ntrain_dataset = Dataset.from_pandas(train_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:47:52.039086Z","iopub.execute_input":"2024-02-15T09:47:52.039380Z","iopub.status.idle":"2024-02-15T09:47:52.091733Z","shell.execute_reply.started":"2024-02-15T09:47:52.039355Z","shell.execute_reply":"2024-02-15T09:47:52.090940Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# loading base model and tokenizers\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    CFG.base_model,\n    num_labels=1,\n\n)\n\ntokenizer = AutoTokenizer.from_pretrained(CFG.base_model)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:47:52.096569Z","iopub.execute_input":"2024-02-15T09:47:52.096909Z","iopub.status.idle":"2024-02-15T09:48:09.340752Z","shell.execute_reply.started":"2024-02-15T09:47:52.096881Z","shell.execute_reply":"2024-02-15T09:48:09.339736Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/huggingfacedebertav3variants/deberta-v3-large and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'classifier.weight', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"peft_config = LoraConfig(\n    r=8, lora_alpha=4, task_type=TaskType.SEQ_CLS, lora_dropout=0.1, \n    bias=\"none\", inference_mode=False, target_modules=[\"query_proj\", \"value_proj\"]\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:48:09.341948Z","iopub.execute_input":"2024-02-15T09:48:09.342230Z","iopub.status.idle":"2024-02-15T09:48:09.347153Z","shell.execute_reply.started":"2024-02-15T09:48:09.342207Z","shell.execute_reply":"2024-02-15T09:48:09.346274Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:48:09.348677Z","iopub.execute_input":"2024-02-15T09:48:09.349009Z","iopub.status.idle":"2024-02-15T09:48:10.054055Z","shell.execute_reply.started":"2024-02-15T09:48:09.348985Z","shell.execute_reply":"2024-02-15T09:48:10.053019Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"trainable params: 788,482 || all params: 435,850,242 || trainable%: 0.1809066335220711\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    new_examples = {\n        \"input_ids_chosen\": [],\n        \"attention_mask_chosen\": [],\n        \"input_ids_rejected\": [],\n        \"attention_mask_rejected\": [],\n    }\n    for chosen, rejected in zip(examples[\"chosen\"], examples[\"rejected\"]):\n        tokenized_j = tokenizer(chosen, truncation=True)\n        tokenized_k = tokenizer(rejected, truncation=True)\n\n        new_examples[\"input_ids_chosen\"].append(tokenized_j[\"input_ids\"])\n        new_examples[\"attention_mask_chosen\"].append(tokenized_j[\"attention_mask\"])\n        new_examples[\"input_ids_rejected\"].append(tokenized_k[\"input_ids\"])\n        new_examples[\"attention_mask_rejected\"].append(tokenized_k[\"attention_mask\"])\n\n    return new_examples\n\ntrain_dataset = train_dataset.map(\n    preprocess_function,\n    batched=True,\n    num_proc=4,\n)\ntrain_dataset = train_dataset.filter(\n    lambda x: len(x[\"input_ids_chosen\"]) <= 256\n    and len(x[\"input_ids_rejected\"]) <= 256\n)\n\n\ntest_dataset = test_dataset.map(\n    preprocess_function,\n    batched=True,\n    num_proc=4,\n)\ntest_dataset = test_dataset.filter(\n    lambda x: len(x[\"input_ids_chosen\"]) <= 2048\n    and len(x[\"input_ids_rejected\"]) <= 2048\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:48:10.055358Z","iopub.execute_input":"2024-02-15T09:48:10.055679Z","iopub.status.idle":"2024-02-15T09:48:19.857630Z","shell.execute_reply.started":"2024-02-15T09:48:10.055651Z","shell.execute_reply":"2024-02-15T09:48:19.856415Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/30132 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7e8f9facf9d43c18666ca28126454f6"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/30132 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b483d42b1861468c9f169529473c2846"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"289c882d46de4a16ba24a478a2923490"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bde04e174f744d69a6b0a0afd57a323a"}},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='op',\n    overwrite_output_dir = True,\n    warmup_ratio=0.1,\n    lr_scheduler_type='cosine',\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=1,\n    gradient_accumulation_steps=2,\n    learning_rate=2e-4,\n    remove_unused_columns=False,\n    optim=\"adafactor\",\n    logging_steps=250,\n    eval_steps=250,\n    evaluation_strategy='steps',\n    load_best_model_at_end=True,\n    save_total_limit = 2,\n    fp16=True,\n    bf16=False,\n    weight_decay=0.01,\n    report_to=\"none\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:48:19.859501Z","iopub.execute_input":"2024-02-15T09:48:19.859868Z","iopub.status.idle":"2024-02-15T09:48:19.932630Z","shell.execute_reply.started":"2024-02-15T09:48:19.859833Z","shell.execute_reply":"2024-02-15T09:48:19.931654Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"trainer = RewardTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    peft_config=peft_config,\n    max_length=256,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:48:19.933878Z","iopub.execute_input":"2024-02-15T09:48:19.934177Z","iopub.status.idle":"2024-02-15T09:48:20.675356Z","shell.execute_reply.started":"2024-02-15T09:48:19.934135Z","shell.execute_reply":"2024-02-15T09:48:20.674269Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.config.use_cache = False\ntrainer.train()\ntrainer.save_model('deberta_adapter')\n\ndel model\n\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-02-15T09:48:20.676872Z","iopub.execute_input":"2024-02-15T09:48:20.677613Z","iopub.status.idle":"2024-02-15T10:12:59.166062Z","shell.execute_reply.started":"2024-02-15T09:48:20.677575Z","shell.execute_reply":"2024-02-15T10:12:59.165202Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2411: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\nCould not estimate the number of tokens of the input, floating-point operations will not be computed\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1883' max='1883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1883/1883 24:35, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>250</td>\n      <td>0.695500</td>\n      <td>0.692644</td>\n      <td>0.672500</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.657300</td>\n      <td>0.559921</td>\n      <td>0.855000</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.570800</td>\n      <td>0.473095</td>\n      <td>0.867500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.534000</td>\n      <td>0.422163</td>\n      <td>0.870000</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.499300</td>\n      <td>0.411132</td>\n      <td>0.872500</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.500800</td>\n      <td>0.408092</td>\n      <td>0.875000</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.525700</td>\n      <td>0.407692</td>\n      <td>0.870000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2411: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2411: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2411: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# loading original training data for evaluation.\ndf = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-02-15T10:12:59.168117Z","iopub.execute_input":"2024-02-15T10:12:59.168828Z","iopub.status.idle":"2024-02-15T10:12:59.180610Z","shell.execute_reply.started":"2024-02-15T10:12:59.168796Z","shell.execute_reply":"2024-02-15T10:12:59.179833Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def get_score(model, tokenizer, prompt, response):\n    inputs = tokenizer(prompt + ' ' + response, return_tensors=\"pt\", max_length=2048, padding='longest', truncation=True).to('cuda')\n    model.to('cuda')\n    model.eval()\n    with torch.autocast('cuda', dtype=torch.float16):\n        outputs = model(input_ids = inputs['input_ids'], attention_mask=inputs['attention_mask'])\n    logits = outputs.logits\n\n    return logits.item()\n\ndef get_top_3_winners(model, tokenizer, prompt, response_options):\n    scores = []\n    for index, response in enumerate(response_options):\n        score = get_score(model, tokenizer, prompt, response)\n        scores.append((index, score))\n\n    \n    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n    \n    top_3_winners = sorted_scores[:3]\n    top_3_winners = [t[0] for t in top_3_winners]\n\n    int_to_string = {\n    0: 'A',\n    1: 'B',\n    2: 'C',\n    3: 'D',\n    4: 'E'\n    }\n\n    top_3_winners = [int_to_string[val] for val in top_3_winners]\n\n    \n    return top_3_winners","metadata":{"execution":{"iopub.status.busy":"2024-02-15T10:12:59.181940Z","iopub.execute_input":"2024-02-15T10:12:59.182322Z","iopub.status.idle":"2024-02-15T10:12:59.192748Z","shell.execute_reply.started":"2024-02-15T10:12:59.182285Z","shell.execute_reply":"2024-02-15T10:12:59.191923Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"preds = []\nfor _, row in tqdm(df.iterrows()):\n    prompt = row['prompt']\n    response_options = [\n        row['A'],\n        row['B'],\n        row['C'],\n        row['D'],\n        row['E']\n    ]\n    top_3_winners = get_top_3_winners(trainer.model, tokenizer, prompt, response_options)\n    preds.append(top_3_winners)\n    \nfinal_preds = [' '.join(pred) for pred in preds]","metadata":{"execution":{"iopub.status.busy":"2024-02-15T10:12:59.193796Z","iopub.execute_input":"2024-02-15T10:12:59.194076Z","iopub.status.idle":"2024-02-15T10:14:38.102923Z","shell.execute_reply.started":"2024-02-15T10:12:59.194051Z","shell.execute_reply":"2024-02-15T10:14:38.101886Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f27c846af1348d2b4b6000486b5e197"}},"metadata":{}}]},{"cell_type":"code","source":"# source https://www.kaggle.com/code/philippsinger/h2ogpt-perplexity-ranking\n\ndef precision_at_k(r, k):\n    \"\"\"Precision at k\"\"\"\n    assert k <= len(r)\n    assert k != 0\n    return sum(int(x) for x in r[:k]) / k\n\ndef MAP_at_3(predictions, true_items):\n    \"\"\"Score is mean average precision at 3\"\"\"\n    U = len(predictions)\n    map_at_3 = 0.0\n    for u in range(U):\n        user_preds = predictions[u]\n        user_true = true_items[u]\n        user_results = [1 if item == user_true else 0 for item in user_preds]\n        for k in range(min(len(user_preds), 3)):\n            map_at_3 += precision_at_k(user_results, k+1) * user_results[k]\n    return map_at_3 / U\n\n\nMAP_at_3(final_preds, df['answer'])","metadata":{"execution":{"iopub.status.busy":"2024-02-15T10:14:38.104315Z","iopub.execute_input":"2024-02-15T10:14:38.104622Z","iopub.status.idle":"2024-02-15T10:14:38.118587Z","shell.execute_reply.started":"2024-02-15T10:14:38.104593Z","shell.execute_reply":"2024-02-15T10:14:38.117625Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"0.7516666666666666"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\npreds = []\nfor _, row in tqdm(df.iterrows()):\n    prompt = row['prompt']\n    response_options = [\n        row['A'],\n        row['B'],\n        row['C'],\n        row['D'],\n        row['E']\n    ]\n    top_3_winners = get_top_3_winners(trainer.model, tokenizer, prompt, response_options)\n    preds.append(top_3_winners)\nfinal_preds = [' '.join(pred) for pred in preds]","metadata":{"execution":{"iopub.status.busy":"2024-02-15T10:14:38.119836Z","iopub.execute_input":"2024-02-15T10:14:38.120359Z","iopub.status.idle":"2024-02-15T10:16:16.675469Z","shell.execute_reply.started":"2024-02-15T10:14:38.120332Z","shell.execute_reply":"2024-02-15T10:16:16.674422Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49e46b3e7a66430a9f7a0b6507ce2559"}},"metadata":{}}]},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/sample_submission.csv')\nsub['prediction'] = final_preds","metadata":{"execution":{"iopub.status.busy":"2024-02-15T10:16:16.676814Z","iopub.execute_input":"2024-02-15T10:16:16.677123Z","iopub.status.idle":"2024-02-15T10:16:16.689477Z","shell.execute_reply.started":"2024-02-15T10:16:16.677097Z","shell.execute_reply":"2024-02-15T10:16:16.688445Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)\npd.read_csv('submission.csv').head()","metadata":{"execution":{"iopub.status.busy":"2024-02-15T10:16:16.690726Z","iopub.execute_input":"2024-02-15T10:16:16.690998Z","iopub.status.idle":"2024-02-15T10:16:16.714678Z","shell.execute_reply.started":"2024-02-15T10:16:16.690975Z","shell.execute_reply":"2024-02-15T10:16:16.713736Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"   id prediction\n0   0      D B E\n1   1      A B C\n2   2      A C E\n3   3      C B A\n4   4      D A B","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>D B E</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>A B C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>A C E</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>C B A</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>D A B</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}